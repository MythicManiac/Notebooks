{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code generation with an RNN\n",
    "Modified from https://www.tensorflow.org/tutorials/text/text_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://raw.githubusercontent.com/risk-of-thunder/Thunderstore/master/django/repository/models.py\n",
      "24576/16961 [===========================================] - 0s 1us/step\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.keras.utils.get_file(\n",
    "    \"code.txt\",\n",
    "    \"https://raw.githubusercontent.com/risk-of-thunder/Thunderstore/master/django/repository/models.py\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import re\n",
      "import uuid\n",
      "\n",
      "from datetime import timedelta\n",
      "from distutils.version import StrictVersion\n",
      "\n",
      "from django.core.exceptions import ValidationError\n",
      "from ipware import get_client_ip\n",
      "\n",
      "from django.conf import settings\n",
      "from django.core.files.storage im\n"
     ]
    }
   ],
   "source": [
    "text = open(dataset, \"r\").read()\n",
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 unique characters in dataset\n",
      "['\\n', ' ', '!', '\"', '#', '%', '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '4', '5', '6', '7', '8', '9', ':', '<', '=', '>', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '}', '~']\n"
     ]
    }
   ],
   "source": [
    "vocabulary = sorted(set(text))\n",
    "print(f\"{len(vocabulary)} unique characters in dataset\")\n",
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_to_index = {\n",
    "    character: index\n",
    "    for index, character\n",
    "    in enumerate(vocabulary)\n",
    "}\n",
    "index_to_character = np.array(vocabulary)\n",
    "\n",
    "vectorized_dataset = np.array([\n",
    "    character_to_index[character]\n",
    "    for character in text\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"\\n\": 0,\n",
      "    \" \": 1,\n",
      "    \"!\": 2,\n",
      "    \"\\\"\": 3,\n",
      "    \"#\": 4,\n",
      "    \"%\": 5,\n",
      "    \"(\": 6,\n",
      "    \")\": 7,\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(character_to_index, indent=4)[:100] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character to integer mapping example\n",
      "import re\n",
      "imp\n",
      "[63 67 70 69 72 74  1 72 59  0 63 67 70]\n"
     ]
    }
   ],
   "source": [
    "print(\"Character to integer mapping example\")\n",
    "print(text[:13])\n",
    "print(vectorized_dataset[:13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 167 examples per epoch\n"
     ]
    }
   ],
   "source": [
    "maximum_sequence_length = 100\n",
    "examples_per_epoch = len(text) // (maximum_sequence_length + 1)\n",
    "print(f\"Training with {examples_per_epoch} examples per epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i\n",
      "m\n",
      "p\n",
      "o\n",
      "r\n"
     ]
    }
   ],
   "source": [
    "dataset_helper = tf.data.Dataset.from_tensor_slices(vectorized_dataset)\n",
    "for i in dataset_helper.take(5):\n",
    "    print(index_to_character[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'import re\\nimport uuid\\n\\nfrom datetime import timedelta\\nfrom distutils.version import StrictVersion\\n\\nfr'\n",
      "'om django.core.exceptions import ValidationError\\nfrom ipware import get_client_ip\\n\\nfrom django.conf i'\n",
      "'mport settings\\nfrom django.core.files.storage import get_storage_class\\nfrom django.db import models, '\n",
      "'transaction\\nfrom django.db.models import Case, When, Sum, Q, signals\\nfrom django.urls import reverse\\n'\n",
      "'from django.utils import timezone\\nfrom django.utils.functional import cached_property\\n\\nfrom core.cach'\n"
     ]
    }
   ],
   "source": [
    "sequences = dataset_helper.batch(\n",
    "    maximum_sequence_length + 1,\n",
    "    drop_remainder=True\n",
    ")\n",
    "for item in sequences.take(5):\n",
    "    print(repr(\"\".join(index_to_character[item.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: ((100,), (100,)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_input_target(sequence):\n",
    "    input_data = sequence[:-1]\n",
    "    target_data = sequence[1:]\n",
    "    return input_data, target_data\n",
    "\n",
    "prepared_dataset = sequences.map(split_input_target)\n",
    "prepared_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data: 'import re\\nimport uuid\\n\\nfrom datetime import timedelta\\nfrom distutils.version import StrictVersion\\n\\nf'\n",
      "Target data: 'mport re\\nimport uuid\\n\\nfrom datetime import timedelta\\nfrom distutils.version import StrictVersion\\n\\nfr'\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in prepared_dataset.take(1):\n",
    "    print(f\"Input data:\", repr(\"\".join(index_to_character[input_example.numpy()])))\n",
    "    print(f\"Target data:\", repr(\"\".join(index_to_character[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "shuffled_dataset = (\n",
    "    prepared_dataset\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    ")\n",
    "\n",
    "shuffled_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = len(vocabulary)\n",
    "# Tutorial had the embedding dimension at 256, but after looking up some\n",
    "# metrics and what it should be based on, I decided to drop it down to 64.\n",
    "# See https://en.wikipedia.org/wiki/Word2vec#Dimensionality\n",
    "# Also https://datascience.stackexchange.com/a/48194\n",
    "embedding_dimension = 64\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (64, None, 64)            5376      \n",
      "_________________________________________________________________\n",
      "gru_4 (GRU)                  (64, None, 1024)          3348480   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (64, None, 84)            86100     \n",
      "=================================================================\n",
      "Total params: 3,439,956\n",
      "Trainable params: 3,439,956\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "checkpoint_dir = \"./training-checkpoints/code-generation-with-an-rnn\"\n",
    "def build_model(vocabulary_size, embedding_dimension, rnn_units, batch_size):\n",
    "    model =  tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(\n",
    "            vocabulary_size,\n",
    "            embedding_dimension,\n",
    "            batch_input_shape=[batch_size, None]\n",
    "        ),\n",
    "        tf.keras.layers.GRU(\n",
    "            rnn_units,\n",
    "            return_sequences=True,\n",
    "            stateful=True,\n",
    "            recurrent_initializer=\"glorot_uniform\",\n",
    "        ),\n",
    "        tf.keras.layers.Dense(vocabulary_size),\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "model = build_model(\n",
    "    vocabulary_size=vocabulary_size,\n",
    "    embedding_dimension=embedding_dimension,\n",
    "    rnn_units=rnn_units,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "if latest:\n",
    "    model.load_weights(latest)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 84) # (batch_size, sequence_length, vocabulary_size)\n"
     ]
    }
   ],
   "source": [
    "for input_batch, target_batch in shuffled_dataset.take(1):\n",
    "    predictions = model(input_batch)\n",
    "    print(predictions.shape, \"# (batch_size, sequence_length, vocabulary_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([40, 50, 78, 23, 60, 16, 65, 74, 25, 24, 38, 35, 79, 25, 76, 27, 72,\n",
       "       52, 18, 52, 61, 83, 70, 30, 44, 65, 40, 42, 65, 16,  5, 39, 12, 13,\n",
       "       51, 16, 24, 24, 81, 26, 51, 28, 81, 24, 35, 81, 55, 23, 31, 59, 22,\n",
       "       25, 77,  8, 28, 30, 26, 48, 59, 12, 83, 32, 36, 27, 65, 60, 78, 22,\n",
       "        9, 34,  1, 13, 55, 33, 63, 79, 69, 54, 82, 51, 53, 32, 20, 15, 43,\n",
       "       62, 18, 39, 83, 77, 65, 80, 80, 20, 44, 33, 28, 20, 35, 80],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apparently random sampling should be used rather than argmax to avoid loops.\n",
    "# So this piece of code uses a the output value as a probability, rather\n",
    "# than just choosing the one that's highest.\n",
    "sampled_indices = tf.random.categorical(predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()\n",
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " 'validate_cache(CacheBustCondition.any_package_updated)\\n\\n    @staticmethod\\n    def post_delete(sender' \n",
      "\n",
      "Output:\n",
      " 'NXx:f2kt=<LHy=v@r[5[g~pCRkNPk2%M./Z2<<{>ZA{<H{a:De9=w*AC>Ve.~EI@kfx9+G /aFiyo_}Z]E71Qh5M~wkzz7RFA7Hz'\n"
     ]
    }
   ],
   "source": [
    "print(\"Input:\\n\", repr(\"\".join(index_to_character[input_batch[0]])), \"\\n\")\n",
    "print(\"Output:\\n\", repr(\"\".join(index_to_character[sampled_indices])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions shape (batch_size, sequence_length, vocabulary_size)\n",
      "(64, 100, 84) \n",
      "\n",
      "scalar_loss: 4.429997\n"
     ]
    }
   ],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(\n",
    "        labels,\n",
    "        logits,\n",
    "        from_logits=True,\n",
    "    )\n",
    "\n",
    "batch_loss = loss(target_batch, predictions)\n",
    "print(\"Predictions shape (batch_size, sequence_length, vocabulary_size)\")\n",
    "print(predictions.shape, \"\\n\")\n",
    "print(\"scalar_loss:\", batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_prefix = os.path.abspath(\n",
    "    os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    ")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 2 steps\n",
      "Epoch 1/90\n",
      "2/2 [==============================] - 1s 512ms/step - loss: 1.7890\n",
      "Epoch 2/90\n",
      "2/2 [==============================] - 1s 525ms/step - loss: 1.7493\n",
      "Epoch 3/90\n",
      "2/2 [==============================] - 1s 541ms/step - loss: 1.7151\n",
      "Epoch 4/90\n",
      "2/2 [==============================] - 1s 513ms/step - loss: 1.7148\n",
      "Epoch 5/90\n",
      "2/2 [==============================] - 1s 524ms/step - loss: 1.6943\n",
      "Epoch 6/90\n",
      "2/2 [==============================] - 1s 478ms/step - loss: 1.6909\n",
      "Epoch 7/90\n",
      "2/2 [==============================] - 1s 513ms/step - loss: 1.6795\n",
      "Epoch 8/90\n",
      "2/2 [==============================] - 1s 500ms/step - loss: 1.6454\n",
      "Epoch 9/90\n",
      "2/2 [==============================] - 1s 623ms/step - loss: 1.6035\n",
      "Epoch 10/90\n",
      "2/2 [==============================] - 1s 570ms/step - loss: 1.6161\n",
      "Epoch 11/90\n",
      "2/2 [==============================] - 1s 565ms/step - loss: 1.6244\n",
      "Epoch 12/90\n",
      "2/2 [==============================] - 1s 512ms/step - loss: 1.5525\n",
      "Epoch 13/90\n",
      "2/2 [==============================] - 1s 559ms/step - loss: 1.5663\n",
      "Epoch 14/90\n",
      "2/2 [==============================] - 1s 547ms/step - loss: 1.5405\n",
      "Epoch 15/90\n",
      "2/2 [==============================] - 1s 582ms/step - loss: 1.5094\n",
      "Epoch 16/90\n",
      "2/2 [==============================] - 1s 530ms/step - loss: 1.4986\n",
      "Epoch 17/90\n",
      "2/2 [==============================] - 1s 559ms/step - loss: 1.4890\n",
      "Epoch 18/90\n",
      "2/2 [==============================] - 1s 587ms/step - loss: 1.4739\n",
      "Epoch 19/90\n",
      "2/2 [==============================] - 1s 634ms/step - loss: 1.4652\n",
      "Epoch 20/90\n",
      "2/2 [==============================] - 1s 531ms/step - loss: 1.4233\n",
      "Epoch 21/90\n",
      "2/2 [==============================] - 1s 588ms/step - loss: 1.3931\n",
      "Epoch 22/90\n",
      "2/2 [==============================] - 1s 582ms/step - loss: 1.3321\n",
      "Epoch 23/90\n",
      "2/2 [==============================] - 1s 600ms/step - loss: 1.3905\n",
      "Epoch 24/90\n",
      "2/2 [==============================] - 1s 558ms/step - loss: 1.2956\n",
      "Epoch 25/90\n",
      "2/2 [==============================] - 1s 594ms/step - loss: 1.3201\n",
      "Epoch 26/90\n",
      "2/2 [==============================] - 1s 593ms/step - loss: 1.3404\n",
      "Epoch 27/90\n",
      "2/2 [==============================] - 1s 571ms/step - loss: 1.2845\n",
      "Epoch 28/90\n",
      "2/2 [==============================] - 1s 610ms/step - loss: 1.2523\n",
      "Epoch 29/90\n",
      "2/2 [==============================] - 1s 553ms/step - loss: 1.2452\n",
      "Epoch 30/90\n",
      "2/2 [==============================] - 1s 576ms/step - loss: 1.2345\n",
      "Epoch 31/90\n",
      "2/2 [==============================] - 1s 553ms/step - loss: 1.2111\n",
      "Epoch 32/90\n",
      "2/2 [==============================] - 1s 646ms/step - loss: 1.1578\n",
      "Epoch 33/90\n",
      "2/2 [==============================] - 1s 610ms/step - loss: 1.1981\n",
      "Epoch 34/90\n",
      "2/2 [==============================] - 1s 611ms/step - loss: 1.1351\n",
      "Epoch 35/90\n",
      "2/2 [==============================] - 1s 617ms/step - loss: 1.0965\n",
      "Epoch 36/90\n",
      "2/2 [==============================] - 1s 542ms/step - loss: 1.1222\n",
      "Epoch 37/90\n",
      "2/2 [==============================] - 1s 675ms/step - loss: 1.0813\n",
      "Epoch 38/90\n",
      "2/2 [==============================] - 1s 594ms/step - loss: 1.0682\n",
      "Epoch 39/90\n",
      "2/2 [==============================] - 1s 565ms/step - loss: 1.0848\n",
      "Epoch 40/90\n",
      "2/2 [==============================] - 1s 640ms/step - loss: 1.0247\n",
      "Epoch 41/90\n",
      "2/2 [==============================] - 1s 571ms/step - loss: 1.0245\n",
      "Epoch 42/90\n",
      "2/2 [==============================] - 1s 553ms/step - loss: 0.9761\n",
      "Epoch 43/90\n",
      "2/2 [==============================] - 2s 836ms/step - loss: 0.9690\n",
      "Epoch 44/90\n",
      "2/2 [==============================] - 2s 968ms/step - loss: 0.9879\n",
      "Epoch 45/90\n",
      "2/2 [==============================] - 2s 894ms/step - loss: 0.9154\n",
      "Epoch 46/90\n",
      "2/2 [==============================] - 2s 940ms/step - loss: 0.9608\n",
      "Epoch 47/90\n",
      "2/2 [==============================] - 2s 930ms/step - loss: 0.9052\n",
      "Epoch 48/90\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.8988\n",
      "Epoch 49/90\n",
      "2/2 [==============================] - 2s 828ms/step - loss: 0.8812\n",
      "Epoch 50/90\n",
      "2/2 [==============================] - 2s 882ms/step - loss: 0.8582\n",
      "Epoch 51/90\n",
      "2/2 [==============================] - 1s 744ms/step - loss: 0.8375\n",
      "Epoch 52/90\n",
      "2/2 [==============================] - 1s 709ms/step - loss: 0.8298\n",
      "Epoch 53/90\n",
      "2/2 [==============================] - 1s 616ms/step - loss: 0.8116\n",
      "Epoch 54/90\n",
      "2/2 [==============================] - 1s 605ms/step - loss: 0.7946\n",
      "Epoch 55/90\n",
      "2/2 [==============================] - 1s 548ms/step - loss: 0.7731\n",
      "Epoch 56/90\n",
      "2/2 [==============================] - 1s 530ms/step - loss: 0.7667\n",
      "Epoch 57/90\n",
      "2/2 [==============================] - 1s 674ms/step - loss: 0.7298\n",
      "Epoch 58/90\n",
      "2/2 [==============================] - 1s 576ms/step - loss: 0.7167\n",
      "Epoch 59/90\n",
      "2/2 [==============================] - 1s 530ms/step - loss: 0.7044\n",
      "Epoch 60/90\n",
      "2/2 [==============================] - 1s 571ms/step - loss: 0.7068\n",
      "Epoch 61/90\n",
      "2/2 [==============================] - 1s 628ms/step - loss: 0.6728\n",
      "Epoch 62/90\n",
      "2/2 [==============================] - 1s 570ms/step - loss: 0.6816\n",
      "Epoch 63/90\n",
      "2/2 [==============================] - 1s 525ms/step - loss: 0.6622\n",
      "Epoch 64/90\n",
      "2/2 [==============================] - 1s 577ms/step - loss: 0.6561\n",
      "Epoch 65/90\n",
      "2/2 [==============================] - 1s 553ms/step - loss: 0.6323\n",
      "Epoch 66/90\n",
      "2/2 [==============================] - 1s 605ms/step - loss: 0.6040\n",
      "Epoch 67/90\n",
      "2/2 [==============================] - 1s 559ms/step - loss: 0.6082\n",
      "Epoch 68/90\n",
      "2/2 [==============================] - 1s 570ms/step - loss: 0.6227\n",
      "Epoch 69/90\n",
      "2/2 [==============================] - 1s 537ms/step - loss: 0.5911\n",
      "Epoch 70/90\n",
      "2/2 [==============================] - 1s 570ms/step - loss: 0.5857\n",
      "Epoch 71/90\n",
      "2/2 [==============================] - 1s 559ms/step - loss: 0.5653\n",
      "Epoch 72/90\n",
      "2/2 [==============================] - 1s 617ms/step - loss: 0.5612\n",
      "Epoch 73/90\n",
      "2/2 [==============================] - 1s 559ms/step - loss: 0.5507\n",
      "Epoch 74/90\n",
      "2/2 [==============================] - 1s 570ms/step - loss: 0.5211\n",
      "Epoch 75/90\n",
      "2/2 [==============================] - 1s 548ms/step - loss: 0.5264\n",
      "Epoch 76/90\n",
      "2/2 [==============================] - 1s 570ms/step - loss: 0.5246\n",
      "Epoch 77/90\n",
      "2/2 [==============================] - 1s 587ms/step - loss: 0.5013\n",
      "Epoch 78/90\n",
      "2/2 [==============================] - 1s 547ms/step - loss: 0.4997\n",
      "Epoch 79/90\n",
      "2/2 [==============================] - 1s 577ms/step - loss: 0.4847\n",
      "Epoch 80/90\n",
      "2/2 [==============================] - 1s 530ms/step - loss: 0.4711\n",
      "Epoch 81/90\n",
      "2/2 [==============================] - 1s 519ms/step - loss: 0.4623\n",
      "Epoch 82/90\n",
      "2/2 [==============================] - 1s 560ms/step - loss: 0.4584\n",
      "Epoch 83/90\n",
      "2/2 [==============================] - 1s 571ms/step - loss: 0.4477\n",
      "Epoch 84/90\n",
      "2/2 [==============================] - 1s 536ms/step - loss: 0.4472\n",
      "Epoch 85/90\n",
      "2/2 [==============================] - 1s 582ms/step - loss: 0.4328\n",
      "Epoch 86/90\n",
      "2/2 [==============================] - 1s 519ms/step - loss: 0.4120\n",
      "Epoch 87/90\n",
      "2/2 [==============================] - 1s 559ms/step - loss: 0.4168\n",
      "Epoch 88/90\n",
      "2/2 [==============================] - 1s 577ms/step - loss: 0.4047\n",
      "Epoch 89/90\n",
      "2/2 [==============================] - 1s 552ms/step - loss: 0.4046\n",
      "Epoch 90/90\n",
      "2/2 [==============================] - 1s 582ms/step - loss: 0.3929\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    shuffled_dataset,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[checkpoint_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (1, None, 64)             5376      \n",
      "_________________________________________________________________\n",
      "gru_5 (GRU)                  (1, None, 1024)           3348480   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (1, None, 84)             86100     \n",
      "=================================================================\n",
      "Total params: 3,439,956\n",
      "Trainable params: 3,439,956\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(\n",
    "    vocabulary_size,\n",
    "    embedding_dimension,\n",
    "    rnn_units,\n",
    "    batch_size=1,\n",
    ")\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.build(tf.TensorShape([1, None]))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "    characters_to_generate = 1000\n",
    "    \n",
    "    input_eval = [\n",
    "        character_to_index[character]\n",
    "        for character in start_string\n",
    "    ]\n",
    "    # tf.expand_dims inserts a dimension at the specified index.\n",
    "    # In this case it converts our shape from (n,) to (1, n,)\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "    \n",
    "    generated_output = []\n",
    "    \n",
    "    temperature = 1.0\n",
    "    \n",
    "    model.reset_states()\n",
    "    for i in range(characters_to_generate):\n",
    "        predictions = model(input_eval)\n",
    "        # tf.squeeze here does the opposite of tf.expand_dims\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        \n",
    "        predictions /= temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)\n",
    "        predicted_id = predicted_id[-1, 0].numpy()\n",
    "        \n",
    "        # Pass in the predicted character as input on the next round\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "        generated_output.append(index_to_character[predicted_id])\n",
    "    \n",
    "    return f\"{start_string}{''.join(generated_output)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import Charecest,\n",
      "        identitie=Fadse,\n",
      "        ingtance   modelsilasFarlatt,\n",
      "            re_urencreremendencies\",\n",
      "        instanc,    re.chertetitt(on_wenge,= \", \"  )\n",
      "    in_ self.lase_download_counter_diwnEoritisy(self):\n",
      "        return self.latest.depdid = \",\n",
      "            \"name\": self.packages.anloadency\n",
      "\n",
      "    @cached_property\n",
      "    def d_pkaclase()\n",
      "        i       rolderValid=True):\n",
      "        kalkowel_at__ange_vels.CAChan_mipertace(self):\n",
      "        return (\n",
      "            \"f     \"relbsif\", self.amon.acle_falef,\n",
      "        related_name=\"versions\",        PackageQhorntid \".lattagn iendet re  return relf.name.dendid\n",
      "    def get_version_pn mepackagl\",\n",
      "        package = medere  members\",\n",
      "        PackageRef\n",
      "\n",
      "    thombel=Tlue,            \", \"hownr\")sert,\n",
      "    )\n",
      "    cachertage=create_torest_ip retatid(uelder identity\n",
      "\n",
      "    def owner(self):\n",
      "       returd salf(sedf):\n",
      "        return self.vanid\n",
      "\n",
      "    @cached_property\n",
      "    def active(self):\n",
      "        return \"restemm\":\n",
      "\n",
      "            \"dependancicalas__icanat\", kwy{d = sol\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=\"import \"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
